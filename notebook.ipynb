{"cells":[{"metadata":{"dc":{"key":"3"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["\n","<p>In this notebook, we will detect how closely related Charles Darwin's books are to each other.</p>\n","<p>To this purpose, we will develop <strong>a content-based book recommendation system</strong>, which will determine which books are close to each other based on how similar the discussed topics are. \n","<p>Here are the books used in the recommendation system below.</p>"]},{"metadata":{"dc":{"key":"3"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["import glob\n","\n","# The books files are contained in this folder\n","folder = \"datasets/\"\n","\n","# Listing all the .txt files sorted alphabetically\n","files = [file for file in glob.glob(folder+\"*.txt\")]\n","files.sort()\n","files"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['datasets/Autobiography.txt',\n"," 'datasets/CoralReefs.txt',\n"," 'datasets/DescentofMan.txt',\n"," 'datasets/DifferentFormsofFlowers.txt',\n"," 'datasets/EffectsCrossSelfFertilization.txt',\n"," 'datasets/ExpressionofEmotionManAnimals.txt',\n"," 'datasets/FormationVegetableMould.txt',\n"," 'datasets/FoundationsOriginofSpecies.txt',\n"," 'datasets/GeologicalObservationsSouthAmerica.txt',\n"," 'datasets/InsectivorousPlants.txt',\n"," 'datasets/LifeandLettersVol1.txt',\n"," 'datasets/LifeandLettersVol2.txt',\n"," 'datasets/MonographCirripedia.txt',\n"," 'datasets/MonographCirripediaVol2.txt',\n"," 'datasets/MovementClimbingPlants.txt',\n"," 'datasets/OriginofSpecies.txt',\n"," 'datasets/PowerMovementPlants.txt',\n"," 'datasets/VariationPlantsAnimalsDomestication.txt',\n"," 'datasets/VolcanicIslands.txt',\n"," 'datasets/VoyageBeagle.txt']"]},"metadata":{},"execution_count":19}]},{"metadata":{"dc":{"key":"10"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["\n","<p>Loading the contents of each book into Python to do some basic pre-processing to facilitate the downstream analyses. That is creating <strong>a corpus</strong>. Also will store the titles for these books for future reference and print their respective length to get a gauge for their contents.</p>"]},{"metadata":{"dc":{"key":"10"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["import re, os\n","\n","txts = []\n","titles = []\n","\n","for n in files:\n","    f = open(n, encoding='utf-8-sig')\n","    # Removing all non-alpha-numeric characters\n","    pattern = re.compile('[^a-zA-Z0-9\\s]+')\n","    text = pattern.sub('', f.read())\n","\n","    title = os.path.basename(n).split('.')[0]\n","    # Storing the texts and titles of the books in two separate lists\n","    txts.append(text)\n","    titles.append(title)\n","\n","# Printing the length, in characters, of each book\n","[len(t) for t in txts]"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[123229,\n"," 496539,\n"," 1785723,\n"," 616671,\n"," 919542,\n"," 624250,\n"," 342689,\n"," 534797,\n"," 796499,\n"," 904003,\n"," 1047646,\n"," 1014384,\n"," 777741,\n"," 1723333,\n"," 305219,\n"," 919177,\n"," 1094855,\n"," 1084841,\n"," 341193,\n"," 1154047]"]},"metadata":{},"execution_count":20}]},{"metadata":{"dc":{"key":"17"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["\n","<p>For the next parts of this analysis, we will often check the results returned by our method for a given book. For consistency, we will refer to Darwin's most famous book: \"<em>On the Origin of Species</em>.\" Let's find to which index this book is associated.</p>"]},{"metadata":{"dc":{"key":"17"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["titles_idx = {}\n","for i in range(len(titles)):\n","    # Storing the index of the titles for future reference\n","    titles_idx[titles[i]] = i\n","\n","# Print the stored index\n","print(titles_idx['OriginofSpecies'])"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["15\n"]}]},{"metadata":{"dc":{"key":"24"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["\n","<p>Tokenizing and removing stop words from the text.</p>"]},{"metadata":{"dc":{"key":"24"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["# Defined a list of stop words\n","stoplist = set('for a of the and to in to be which some is at that we i who whom show via may my our might as well'.split())\n","\n","txts_lower_case = [txt.casefold() for txt in txts]\n","\n","# Transforming the text into tokens \n","txts_split = [txt.split() for txt in txts_lower_case]\n","\n","# Remove tokens which are part of the list of stop words\n","texts = [[txt for txt in txts_split[i] if txt not in stoplist] for i in range(len(txts_split))]\n","\n","# Printing the first 20 tokens for the \"On the Origin of Species\" book\n","print(texts[titles_idx['OriginofSpecies']][:20])"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['on', 'origin', 'species', 'but', 'with', 'regard', 'material', 'world', 'can', 'least', 'go', 'so', 'far', 'thiswe', 'can', 'perceive', 'events', 'are', 'brought', 'about']\n"]}]},{"metadata":{"dc":{"key":"31"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["\n","Stemming of the tokenized corpus:"]},{"metadata":{"dc":{"key":"31"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["import pickle\n","\n","# Loading the stemmed tokens list from the pregenerated pickle file\n","pick_file = open(\"./datasets/texts_stem.p\", mode='rb')\n","texts_stem = pickle.load(pick_file)\n","\n","# Printing the 20 first stemmed tokens from the \"On the Origin of Species\" book\n","print(texts_stem[titles_idx['OriginofSpecies']][:20])"],"execution_count":24,"outputs":[{"output_type":"error","ename":"UnpicklingError","evalue":"invalid load key, '\\xef'.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-1783a45d6371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Loading the stemmed tokens list from the pregenerated pickle file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpick_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./datasets/texts_stem.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtexts_stem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpick_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Printing the 20 first stemmed tokens from the \"On the Origin of Species\" book\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\xef'."]}]},{"metadata":{"dc":{"key":"38"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["\n","Building a bag-of-words model"]},{"metadata":{"dc":{"key":"38"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["from gensim import corpora\n","\n","# Creating a dictionary from the stemmed tokens\n","dictionary = corpora.Dictionary(texts_stem)\n","\n","bows = [dictionary.doc2bow(book) for book in texts_stem]\n","\n","# Printing the first five elements of the On the Origin of species' BoW model\n","bows[ori][:5]"],"execution_count":7,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'gensim'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-a46022b44e53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Creating a dictionary from the stemmed tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_stem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"]}]},{"metadata":{"dc":{"key":"45"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["\n","Finding the most common words of a given book"]},{"metadata":{"dc":{"key":"45"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["import pandas as pd\n","\n","# Converting the BoW model for \"On the Origin of Species\" into a DataFrame\n","df_bow_origin = pd.DataFrame(bows[ori])\n","\n","# Adding the column names to the DataFrame\n","df_bow_origin.columns = [\"index\", \"occurences\"]\n","df_bow_origin.head()\n","\n","# Adding a column containing the token corresponding to the dictionary index\n","df_bow_origin['token'] = [dictionary[i] for i in df_bow_origin['index']]\n","df_bow_origin.tail()\n","\n","# Sorting the DataFrame by descending number of occurrences and print the first 10 values\n","df_bow_origin.sort_values(by='occurences', ascending=False).head(10)"],"execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"52"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["\n","Building a tf-idf model"]},{"metadata":{"dc":{"key":"52"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["from gensim.models import TfidfModel\n","\n","# Generate the tf-idf model\n","model = TfidfModel(bows)\n","\n","model[bows[ori][:5]]"],"execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"59"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["The results of the tf-idf model"]},{"metadata":{"dc":{"key":"59"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["# Converting the tf-idf model for \"On the Origin of Species\" into a DataFrame\n","df_tfidf = pd.DataFrame(model[bows[ori]])\n","df_tfidf.head()\n","\n","df_tfidf.columns = ['id', 'scores']\n","\n","# Adding the tokens corresponding to the numerical indices for better readability\n","df_tfidf['token'] = [dictionary[i] for i in df_tfidf.id]\n","df_tfidf.tail()\n","\n","df_tfidf.sort_values(by='scores', ascending=False).head(10)"],"execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"66"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["\n","Computing distance between texts"]},{"metadata":{"dc":{"key":"66"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["from gensim import similarities\n","\n","# Computing the similarity matrix (pairwise distance between all texts)\n","sims = similarities.MatrixSimilarity(model[bows])\n","\n","sim_df = pd.DataFrame(list(sims))\n","sim_df.head()\n","\n","sim_df.columns = titles\n","sim_df.index = titles\n","\n","sim_df.head(10)"],"execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"73"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["\n","The book most similar to \"On the Origin of Species\""]},{"metadata":{"dc":{"key":"73"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","# Selecting the column corresponding to \"On the Origin of Species\" and \n","v = sim_df['OriginofSpecies']\n","\n","v_sorted = v.sort_values()\n","v_sorted[:5]\n","\n","plot_sim = v_sorted.plot.barh(x='lab', y='val', rot=0).plot()\n","\n","plt.xlabel(\"Cosine distance\")\n","plt.ylabel(\"\")\n","plt.title(\"Most similar books to 'On the Origin of Species'\")\n"],"execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"80"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":["## Books having similar content"]},{"metadata":{"dc":{"key":"80"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":["from scipy.cluster import hierarchy\n","\n","# Computeing the clusters from the similarity matrix, using the Ward variance minimization algorithm\n","Z = hierarchy.linkage(sim_df, 'ward')\n","\n","# Displaying this result as a horizontal dendrogram\n","a = hierarchy.dendrogram(Z, leaf_font_size=8, labels=sim_df.index, orientation='left')"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}